---
title: "week12notes"
format: html 
---

```{R}
packages <- c(
  "dplyr", 
  "readr", 
  "tidyr", 
  "purrr", 
  "stringr", 
  "corrplot", 
  "car", 
  "caret", 
  "torch", 
  "nnet", 
  "broom",
  "torch",
  "torchvision",
  "e1071",
  "glmnet",
  "nnet",
  "rpart",
  "ISLR2",
  'luz',
  'torchvision'
)

renv::install(packages)
sapply(packages, require, character.only=T)
```



## Tuesday April 4th

```{r}
ex <- \(x) ifelse(
  ((abs(x[1]) + 0.05 * rnorm(1) > 0.50 & abs(x[2]) + 0.05 * rnorm(1) > 0.50)) |
  ((abs(x[1]) + 0.05 * rnorm(1) < 0.25 & abs(x[2]) + 0.05 * rnorm(1) < 0.25)),1,0  
)

n <- 300
X <- t(replicate(n, 2 * runif(2) - 1))
y <- apply(X, 1, ex) %>% as.factor()
col <- ifelse(y == 0, 'blue', 'red')
df <- data.frame(y = y, x1 = X[,1], x2 = X[,2])
plot(df$x1, df$x2, col = col, pch = 19)

Xnew <- cbind(
  rep(seq(-1.1, 1.1, length.out = 50), 50),
  rep(seq(-1.1, 1.1, length.out = 50), each = 50)
)

df_new = data.frame(x1 = Xnew[,1], x2 = Xnew[,2])
```


```{r}
Xnew <- cbind(
  rep(seq(-1.1, 1.1, length.out = 50), 50),
  rep(seq(-1.1, 1.1, length.out = 50), each = 50)
)

df_new = data.frame(x1=Xnew[,1], x2=Xnew[,2])

plt <- function(f,x){
  plot(x[,1], x[,2], col=ifelse(f(x) < 0.5, 'blue', 'red'), pch = 22)
  points(df$x1, df$x2, col = ifelse(y == '0', 'blue', 'red'), pch = 19)
}

overview <- function(f){
  predicted <- ifelse(f(df[,1]) < 0.5, 1, 0)
  actual <- df[,1]
  table(predicted, actual)
}
```


#### Neural Network with 1 hidden layer

```{r}
p <- 2
q <- 20

hh1_module <- nn_module(
  initialize = function() {
    self$f <- nn_linear(p,q)
    self$g <- nn_linear(q,1)
    self$a <- nn_relu()
    self$s <- nn_sigmoid()
  },
  forward = function(x) {
    x %>%
      self$f() %>%
      self$a() %>%
      self$g() %>%
      self$s()
  }
)
```


#### Neural Network with 2 hidden layers

```{r}
p <- 2
q1 <- 100
q2 <- 20

hh2_module <- nn_module(
  initialize = function() {
    self$f <- nn_linear(p,q1)
    self$g <- nn_linear(q1,q2)
    self$h <- nn_linear(q2,1)
    self$a <- nn_relu()
    self$s <- nn_sigmoid()
  },
  forward = function(x) {
    x %>%
      self$f() %>%
      self$a() %>%
      self$g() %>%
      self$a() %>%
      self$h() %>%
      self$s()
  }
)

```


```{r}
classifier <- 
  function(train, type = 'nn', ...){
    if(type == 'logistic'){
      f = \(x) glm(y ~ x1 + x2, train, family = binomial()) %>%
        predict(., x, type = 'response')
    }
    else if(type == 'rpart'){
      f = \(x)
        rpart(y ~ x1 + x2, df, method = 'class') %>%
        predict(., x, type = 'class') %>%
        as.numeric(.) - 1
    }
    else if(type == 'svm'){
      f = \(x)
          svm(y ~ x1 + x2, df, kernel = 'radial') %>%
            predict(., x) %>%
            as.numeric(.) - 1
    }
    else if(type == 'nn'){
      X_tensor <- torch_tensor(train[,-1] %>% as.matrix(), dtype = torch_float())
      y_tensor <- torch_tensor(cbind(train$y %>% as.numeric() - 1), dtype = torch_float())
      F <- hh2_module()
      optimizer <- optim_adam(F$parameters, lr = 0.05)
      epochs <- 1000
      
      for (i in 1:epochs){
        loss <- nn_bce_loss()(F(X_tensor), y_tensor)
        optimizer$zero_grad()
        loss$backward()
        optimizer$step()
      }
      f = \(x) as_array(F( torch_tensor(x %>% as.matrix(), dtype = torch_float()) ))
    }
    return(f)
  }

```


```{r}
f <- classifier(df, 'logistic')
plt(f, df_new)
#overview(df)
```

```{r}
f <- classifier(df, 'rpart')
plt(f, df_new)
#overview(df)
```

```{r}
f <- classifier(df, 'svm')
plt(f, df_new)
#overview(df)
```
```{r}
f <- classifier(df, 'nn')
plt(f, df_new)
#overview(df)
```


```{r}
F <- hh1_module()
F( torch_randn(20,2) )
# output would be 20 by 1 tensor, that contains the sigmoid probabilities

# if get rid of activation layer (reLU), output doesn't change since activation is only happening internally (will still see probability values)

# if get rid of sigmoid layer, will still by 20 by 1 tensor that instead shows actual values and not probabilities (may have negative numbers)


F <- hh2_module()
F( torch_randn(20,2) )
```


```r
f <- classifier(df "___") --> "rpart", "nn", ...
plt(f, df_new)
overview(df)
```



Exponentially increasing sin wave
```{r}
generate_data <- function(n, noise = 0.1) {
  x <- seq(1*pi, 1.7*pi, length.out = n)
  y <- exp(x) * (sin(150/x) + rnorm(n, 0, noise))
  data.frame(x = x, y = y)
}

df <- generate_data(200, noise = 0.1)
plot(df$x, df$y, pch=19)
```

```{r}
plt_reg <- function (f, x){
  ynew <- f(x)
  ylim <- range(c(ynew, df$y))
  ylim[1] <- max(c(-800, ylim[1]))
  ylim[2] <- min(c(250, ylim[2]))
  xlim <-range(x)
  plot(df$x, df$y, pch = 22, col = 'red', xlim=xlim, ylim = ylim)
  points(x[,1], ynew, pch=22, type='l')
}  
```


```{r}
#regressor formula is same as classifier except it uses nn_mse_loss() instead of nn_bce_loss()

regressor <- 
  function(train, type = 'nn', ...){
    if(type == 'logistic'){
      f = \(x) glm(y ~ x1 + x2, train, family = binomial()) %>%
        predict(., x, type = 'response')
    }
    else if(type == 'rpart'){
      f = \(x)
        rpart(y ~ x1 + x2, df, method = 'class') %>%
        predict(., x, type = 'class') %>%
        as.numeric(.) - 1
    }
    else if(type == 'svm'){
      f = \(x)
          svm(y ~ x1 + x2, df, kernel = 'radial') %>%
            predict(., x) %>%
            as.numeric(.) - 1
    }
    else if(type == 'nn'){
      X_tensor <- torch_tensor(train[,-1] %>% as.matrix(), dtype = torch_float())
      y_tensor <- torch_tensor(cbind(train$y %>% as.numeric() - 1), dtype = torch_float())
      F <- hh2_module()
      optimizer <- optim_adam(F$parameters, lr = 0.05)
      epochs <- 1000
      
      for (i in 1:epochs){
        loss <- nn_mse_loss()(F(X_tensor), y_tensor)
        optimizer$zero_grad()
        loss$backward()
        optimizer$step()
      }
      f = \(x) as_array(F( torch_tensor(x %>% as.matrix(), dtype = torch_float()) ))
    }
    return(f)
  }

#can change learning rate to mess around with output to get different results
```

```{r}
Xnew <- cbind(
  rep(seq(-1.1, 1.1, length.out = 50), 50),
  rep(seq(-1.1, 1.1, length.out = 50), each = 50)
)

df_new = data.frame(x1=Xnew[,1], x2=Xnew[,2])

plt <- function(f,x){
  plot(x[,1], x[,2], col=ifelse(f(x) < 0.5, 'blue', 'red'), pch = 22)
  points(df$x1, df$x2, col = ifelse(y == '0', 'blue', 'red'), pch = 19)
}

overview <- function(f){
  predicted <- ifelse(f(df[,1]) < 0.5, 1, 0)
  actual <- df[,1]
  table(predicted, actual)
}
```

```{r}
f <- regressor(df, 'svm')
plt(f, df_new)
#overview(df)
```

```{r}

## Thursday April 6th